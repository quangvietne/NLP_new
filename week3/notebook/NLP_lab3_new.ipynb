{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2USixEHfFFV",
        "outputId": "435babed-151f-4096-a252-134c0ac8c292"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models import KeyedVectors\n",
        "import gensim.downloader as api\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "LjdtL0N8ge6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "class WordEmbedder :\n",
        "  def __init__(self, model_name: str) :\n",
        "       print(\"Đang tải mô hình GloVe...\")\n",
        "       self.model = api.load(model_name)\n",
        "       print(\"Mô hình đã tải xong!\")\n",
        "\n",
        "  def get_vector(self, word: str):\n",
        "    if word in self.model :\n",
        "      return self.model[word]\n",
        "    else :\n",
        "      raise ValueError(f\"Từ '{word}' không có trong từ điển của model.\")\n",
        "\n",
        "  def get_similarity(self, word1: str, word2: str):\n",
        "    vec1 = self.get_vector(word1)\n",
        "    vec2 = self.get_vector(word2)\n",
        "    if vec1 is None or vec2 is None:\n",
        "            return None\n",
        "    # Tính cosine similarity: (v1 . v2) / (||v1|| * ||v2||)\n",
        "    dot_product = np.dot(vec1, vec2)\n",
        "    norm1 = np.linalg.norm(vec1)\n",
        "    norm2 = np.linalg.norm(vec2)\n",
        "    if norm1 == 0 or norm2 == 0:\n",
        "            return 0.0\n",
        "    similarity = dot_product / (norm1 * norm2)\n",
        "    return similarity\n",
        "\n",
        "  def get_most_similar(self, word: str, top_n: int = 10):\n",
        "    vec = self.get_vector(word)\n",
        "    if vec is None:\n",
        "            return []\n",
        "\n",
        "        # Tính cosine similarity giữa vector của từ đầu vào và tất cả vector trong từ điển\n",
        "    similarities = []\n",
        "    for vocab_word in self.model.index_to_key:\n",
        "      vocab_vec = self.get_vector(vocab_word)\n",
        "      sim = self.get_similarity(word, vocab_word)\n",
        "      if sim is not None:\n",
        "        similarities.append((vocab_word, sim))\n",
        "\n",
        "    # Sắp xếp theo độ tương tự giảm dần và lấy top_n\n",
        "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "    return similarities[:top_n]\n",
        "\n",
        "  def tokenize(self, text: str) -> list[str]:\n",
        "      text = text.lower()\n",
        "      pattern = r\"\\w+|[^\\w\\s]\"\n",
        "      tokens = re.findall(pattern, text)\n",
        "      return tokens\n",
        "  def embed_document(self, document: str):\n",
        "    tokens = self.tokenize(document)\n",
        "    vectors = []\n",
        "    for token in tokens:\n",
        "        vec = self.get_vector(token)\n",
        "        if vec is not None:\n",
        "            vectors.append(vec)\n",
        "    if not vectors:\n",
        "        return np.zeros(self.model.vector_size)\n",
        "    return np.mean(vectors, axis=0)\n",
        "\n"
      ],
      "metadata": {
        "id": "mmWeVlg0hI2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Khởi tạo với model GloVe\n",
        "embedder = WordEmbedder('glove-wiki-gigaword-50')\n",
        "# Lấy vector của từ 'king'\n",
        "print(embedder.get_vector('king')[:10])  # In 10 giá trị đầu của vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsypumE-mT19",
        "outputId": "917e8a38-e92e-4dea-86e2-d3f6c93a6c32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đang tải mô hình GloVe...\n",
            "Mô hình đã tải xong!\n",
            "[ 0.50451   0.68607  -0.59517  -0.022801  0.60046  -0.13498  -0.08813\n",
            "  0.47377  -0.61798  -0.31012 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tính tương đồng\n",
        "print(\"Similarity between king and queen:\", embedder.get_similarity('king', 'queen'))\n",
        "print(\"Similarity between king and man:\", embedder.get_similarity('king', 'man'))\n",
        "# Tìm top K tương đồng với từ \"computer\"\n",
        "print(embedder.get_most_similar('computer'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7WgDidMnENB",
        "outputId": "24a31735-52f3-4cbe-ba83-d3caf3bfc74f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between king and queen: 0.7839044\n",
            "Similarity between king and man: 0.5309377\n",
            "[('computer', 1.0), ('computers', 0.91650456), ('software', 0.8814993), ('technology', 0.8525559), ('electronic', 0.8125868), ('internet', 0.80604553), ('computing', 0.8026036), ('devices', 0.8016185), ('digital', 0.79917926), ('applications', 0.79127395)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "embed_text = embedder.embed_document('The queen rules the country.')\n",
        "print(embed_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jENWvF_spWir",
        "outputId": "7299d8cf-1c01-4e3b-d27d-99b2a5b8e069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.04564168  0.36530998 -0.55974334  0.04014383  0.09655549  0.15623933\n",
            " -0.33622834 -0.12495166 -0.01031508 -0.5006717   0.18690467  0.17482166\n",
            " -0.268985   -0.03096624  0.36686516  0.29983264  0.01397333 -0.06872118\n",
            " -0.3260683  -0.210115    0.16835399 -0.03151734 -0.06204716  0.04301083\n",
            " -0.06958768 -1.7792168  -0.54365396 -0.06104483 -0.17618     0.009181\n",
            "  3.3916333   0.08742473 -0.4675417  -0.213435    0.02391887 -0.04470453\n",
            "  0.20636833 -0.12902866 -0.28527132 -0.2431805  -0.3114423  -0.03833717\n",
            "  0.11977985 -0.01418401 -0.37086335  0.22069354 -0.28848937 -0.36188802\n",
            " -0.00549529 -0.46997246]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Bonus Task: Training a Word2Vec Model from Scratch"
      ],
      "metadata": {
        "id": "p5fIB6c1_zFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from gensim.models import Word2Vec\n",
        "import os\n",
        "\n",
        "def tokenize(text: str) -> list:\n",
        "    \"\"\"Tokenizer từ Lab 1: Tách từ và dấu bằng regex.\"\"\"\n",
        "    text = text.lower()\n",
        "    pattern = r\"\\w+|[^\\w\\s]\"\n",
        "    tokens = re.findall(pattern, text)\n",
        "    return tokens\n",
        "\n",
        "def read_data(file_path: str) -> list:\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        text = f.read()\n",
        "    tokens = tokenize(text)\n",
        "    return [tokens]\n",
        "\n",
        "def main():\n",
        "    # Bước 1: Đọc dữ liệu\n",
        "    data_path = '/content/en_ewt-ud-train.txt'\n",
        "    if not os.path.exists(data_path):\n",
        "        print(f\"Không tìm thấy file: {data_path}\")\n",
        "        return\n",
        "\n",
        "    print(\"Đang đọc dữ liệu...\")\n",
        "    sentences = read_data(data_path)\n",
        "    print(f\"✅ Đã đọc {len(sentences[0])} tokens\")\n",
        "\n",
        "    # Bước 2: Huấn luyện mô hình Word2Vec\n",
        "    print(\"Đang huấn luyện Word2Vec...\")\n",
        "    model = Word2Vec(\n",
        "        sentences=sentences,\n",
        "        vector_size=10,\n",
        "        window=5,\n",
        "        min_count=2,   # ⚠️ Nên thêm để bỏ từ xuất hiện ít\n",
        "        sg=1,          # ⚙️ Dùng Skip-gram cho ngữ nghĩa tốt hơn\n",
        "        epochs=30\n",
        "    )\n",
        "\n",
        "    # Bước 3: Lưu mô hình\n",
        "    os.makedirs(\"results\", exist_ok=True)  # ⚠️ Thêm dòng này để tránh lỗi thư mục\n",
        "    model_path = 'results/word2vec_ewt.model'\n",
        "    model.save(model_path)\n",
        "    print(f\"✅ Đã lưu mô hình vào {model_path}\")\n",
        "\n",
        "    # Bước 4: Demo sử dụng\n",
        "    print(\"\\nDemo sử dụng mô hình:\")\n",
        "    word = \"woman\"\n",
        "    if word in model.wv:\n",
        "        print(f\"Các từ tương tự với '{word}':\")\n",
        "        similar_words = model.wv.most_similar(word, topn=5)\n",
        "        for w, sim in similar_words:\n",
        "            print(f\"  {w}: {sim:.4f}\")\n",
        "    else:\n",
        "        print(f\"Từ '{word}' không có trong từ điển.\")\n",
        "\n",
        "    analogy_words = ['king', 'woman', 'man']\n",
        "    if all(w in model.wv for w in analogy_words):\n",
        "        print(\"\\nGiải analogy: king - man + woman = ?\")\n",
        "        result = model.wv.most_similar(\n",
        "            positive=['king', 'woman'],\n",
        "            negative=['man'],\n",
        "            topn=5\n",
        "        )\n",
        "        for w, sim in result:\n",
        "            print(f\"  {w}: {sim:.4f}\")\n",
        "    else:\n",
        "        print(\"\\nKhông thể giải analogy vì thiếu từ trong từ điển.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPr70gr7_yej",
        "outputId": "2129de4d-5980-4291-91ef-a1d47f4ffe8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Đang đọc dữ liệu...\n",
            "✅ Đã đọc 217306 tokens\n",
            "Đang huấn luyện Word2Vec...\n",
            "✅ Đã lưu mô hình vào results/word2vec_ewt.model\n",
            "\n",
            "Demo sử dụng mô hình:\n",
            "Các từ tương tự với 'woman':\n",
            "  acquire: 0.9336\n",
            "  rachel: 0.8780\n",
            "  toy: 0.8627\n",
            "  liquidweb: 0.8610\n",
            "  268: 0.8548\n",
            "\n",
            "Giải analogy: king - man + woman = ?\n",
            "  acquire: 0.9056\n",
            "  toy: 0.8872\n",
            "  hybrid: 0.8863\n",
            "  rachel: 0.8400\n",
            "  circulate: 0.8366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MqJ4C_pEp6vN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}