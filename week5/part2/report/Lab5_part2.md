
### ğŸ“Š Báº£ng so sÃ¡nh káº¿t quáº£ Ä‘á»‹nh lÆ°á»£ng

Sau khi huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ cáº£ 4 pipeline, Ä‘Ã¢y lÃ  káº¿t quáº£

| Pipeline | F1-score (Macro) | Test Loss (hoáº·c Val\_loss) |
| :--- | :---: | :---: |
| **TF-IDF + Logistic Regression** | **0.8353** | N/A |
| Word2Vec (Avg) + Dense | 0.3032 | \~2.5184 |
| Embedding (Pre-trained) + LSTM | 0.0418 | \~3.3181 |
| Embedding (Scratch) + LSTM | 0.0005 | \~4.1240 |

**PhÃ¢n tÃ­ch nhanh káº¿t quáº£ Ä‘á»‹nh lÆ°á»£ng:**

Káº¿t quáº£ Ä‘á»‹nh lÆ°á»£ng cho tháº¥y má»™t Ä‘iá»u ráº¥t rÃµ rÃ ng:

1.  **MÃ´ hÃ¬nh cá»• Ä‘iá»ƒn (TF-IDF + Logistic Regression) chiáº¿n tháº¯ng Ã¡p Ä‘áº£o** vá»›i F1-score (macro) lÃªn Ä‘áº¿n 83.53%.
2.  **Táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh Deep Learning Ä‘á»u tháº¥t báº¡i tháº£m háº¡i.** MÃ´ hÃ¬nh "Word2Vec (Avg) + Dense" chá»‰ Ä‘áº¡t F1-score 30.32%, trong khi cáº£ hai mÃ´ hÃ¬nh LSTM Ä‘á»u cho káº¿t quáº£ gáº§n nhÆ° báº±ng 0 (F1-score 4.18% vÃ  0.05%).
3.  **LÃ½ do tháº¥t báº¡i (sÆ¡ bá»™):** CÃ³ hai lÃ½ do chÃ­nh.
      * **Embedding (Pre-trained) + LSTM:** MÃ´ hÃ¬nh nÃ y tháº¥t báº¡i vÃ¬ nÃ³ sá»­ dá»¥ng vector Word2Vec (`w2v_model`) do chÃºng ta tá»± huáº¥n luyá»‡n trÃªn 8954 cÃ¢u (quÃ¡ Ã­t). Cháº¥t lÆ°á»£ng embedding nÃ y ráº¥t tháº¥p, vÃ  viá»‡c chÃºng ta "Ä‘Ã³ng bÄƒng" nÃ³ (`trainable=False`) Ä‘Ã£ khiáº¿n mÃ´ hÃ¬nh khÃ´ng thá»ƒ há»c Ä‘Æ°á»£c.
      * **Embedding (Scratch) + LSTM:** MÃ´ hÃ¬nh nÃ y tháº¥t báº¡i vÃ¬ **Ä‘Ã³i dá»¯ liá»‡u (Data Starvation)**. Táº­p dá»¯ liá»‡u 8954 cÃ¢u lÃ  quÃ¡ nhá» Ä‘á»ƒ mÃ´ hÃ¬nh cÃ³ thá»ƒ há»c Ä‘á»“ng thá»i cáº£ vector embedding láº«n quan há»‡ ngá»¯ nghÄ©a cá»§a LSTM.

-----

### ğŸ§  PhÃ¢n tÃ­ch Ä‘á»‹nh tÃ­nh (Táº¡i sao LSTM khÃ´ng hoáº¡t Ä‘á»™ng?)

ÄÃ¢y lÃ  pháº§n quan trá»ng nháº¥t. TÃ´i Ä‘Ã£ cháº¡y dá»± Ä‘oÃ¡n trÃªn 3 cÃ¢u "khÃ³" (láº¥y tá»« cell code cuá»‘i cÃ¹ng) vÃ  so sÃ¡nh vá»›i nhÃ£n tháº­t (True Labels) Ä‘Ã£ Ä‘Æ°á»£c sá»­a láº¡i cho chÃ­nh xÃ¡c.

  * **CÃ¢u 1 (Phá»§ Ä‘á»‹nh):** `"can you remind me to not call my mom"`
      * **NhÃ£n tháº­t:** `reminder_create`
  * **CÃ¢u 2 (Cáº¥u trÃºc "hoáº·c"):** `"is it going to be sunny or rainy tomorrow"`
      * **NhÃ£n tháº­t:** `weather_query`
  * **CÃ¢u 3 (Phá»¥ thuá»™c xa & Phá»§ Ä‘á»‹nh):** `"find a flight from new york to london but not through paris"`
      * **NhÃ£n tháº­t:** `flight_search`

**Báº£ng káº¿t quáº£ dá»± Ä‘oÃ¡n (Tá»« Cell code cuá»‘i cÃ¹ng):**

| MÃ´ hÃ¬nh | CÃ¢u 1 ("...not call...") | CÃ¢u 2 ("...sunny or rainy...") | CÃ¢u 3 ("...but not through...") |
| :--- | :--- | :--- | :--- |
| **NhÃ£n tháº­t** | **`reminder_create`** | **`weather_query`** | **`flight_search`** |
| TF-IDF + LR | `calendar_set` (SaiÂ¹) | **`weather_query` (ÄÃºng)** | `general_negate` (Sai) |
| W2V + Dense | `general_quirky` (Sai) | `qa_maths` (Sai) | `transport_query` (SaiÂ²) |
| LSTM (Pre-trained) | `general_explain` (Sai) | `music_query` (Sai) | `lists_createoradd` (Sai) |
| LSTM (Scratch) | `iot_coffee` (Sai) | `iot_coffee` (Sai) | `iot_coffee` (Sai) |

-----

#### PhÃ¢n tÃ­ch chi tiáº¿t:

1.  **Hiá»‡n tÆ°á»£ng "Sá»¥p Ä‘á»• mÃ´ hÃ¬nh" (Model Collapse) cá»§a LSTM (Scratch):**

      * ÄÃ¢y lÃ  phÃ¡t hiá»‡n rÃµ rÃ ng nháº¥t. MÃ´ hÃ¬nh "LSTM (Scratch)" Ä‘Ã£ sá»¥p Ä‘á»• hoÃ n toÃ n. NÃ³ dá»± Ä‘oÃ¡n **`iot_coffee` cho má»i cÃ¢u**.
      * **Giáº£i thÃ­ch:** Vá»›i má»™t táº­p dá»¯ liá»‡u quÃ¡ nhá» (8954 máº«u), mÃ´ hÃ¬nh cÃ³ quÃ¡ nhiá»u tham sá»‘ (pháº£i há»c cáº£ Embedding vÃ  LSTM) Ä‘Ã£ khÃ´ng thá»ƒ há»™i tá»¥. NÃ³ chá»‰ há»c Ä‘Æ°á»£c cÃ¡ch dá»± Ä‘oÃ¡n má»™t lá»›p duy nháº¥t Ä‘á»ƒ giáº£m thiá»ƒu loss. MÃ´ hÃ¬nh nÃ y hoÃ n toÃ n vÃ´ dá»¥ng.

2.  **Sá»± tháº¥t báº¡i cá»§a LSTM (Pre-trained) do Embedding kÃ©m:**

      * MÃ´ hÃ¬nh nÃ y cÅ©ng tháº¥t báº¡i, dá»± Ä‘oÃ¡n cÃ¡c lá»›p sai má»™t cÃ¡ch ngáº«u nhiÃªn (`general_explain`, `music_query`, `lists_createoradd`).
      * **Giáº£i thÃ­ch:** MÃ´ hÃ¬nh Word2Vec (`w2v_model`) Ä‘Æ°á»£c huáº¥n luyá»‡n á»Ÿ Task 2 chá»‰ dá»±a trÃªn 8954 cÃ¢u. ÄÃ¢y lÃ  má»™t embedding "rÃ¡c". Khi tÃ´i náº¡p nÃ³ vÃ o LSTM vÃ  Ä‘áº·t `trainable=False`, tÃ´i Ä‘Ã£ buá»™c mÃ´ hÃ¬nh LSTM pháº£i há»c ngá»¯ nghÄ©a dá»±a trÃªn cÃ¡c vector Ä‘áº§u vÃ o vÃ´ nghÄ©a. DÃ¹ kiáº¿n trÃºc LSTM cÃ³ máº¡nh máº½ Ä‘áº¿n Ä‘Ã¢u, nÃ³ cÅ©ng khÃ´ng thá»ƒ há»c Ä‘Æ°á»£c gÃ¬ tá»« Ä‘áº§u vÃ o kÃ©m cháº¥t lÆ°á»£ng (Garbage In, Garbage Out).

3.  **CÃ¢u 1 & 2 (Chiáº¿n tháº¯ng cho TF-IDF):**

      * MÃ´ hÃ¬nh **TF-IDF + LR** dá»± Ä‘oÃ¡n **Ä‘Ãºng** CÃ¢u 2 (`weather_query`) vÃ  **sai** CÃ¢u 1.
      * **(SaiÂ¹) - CÃ¢u 1:** NhÃ£n tháº­t lÃ  `reminder_create`. TF-IDF dá»± Ä‘oÃ¡n `calendar_set`. ÄÃ¢y lÃ  má»™t lá»—i **sai nhÆ°ng cÃ³ thá»ƒ hiá»ƒu Ä‘Æ°á»£c**. Hai intent `reminder_create` (táº¡o nháº¯c nhá»Ÿ) vÃ  `calendar_set` (Ä‘áº·t lá»‹ch) ráº¥t gáº§n nhau vá» máº·t ngá»¯ nghÄ©a vÃ  tá»« khÃ³a (Ä‘á»u dÃ¹ng "remind"). MÃ´ hÃ¬nh Ä‘Ã£ báº¯t Ä‘Ãºng *chá»§ Ä‘á»* nhÆ°ng sai intent cá»¥ thá»ƒ.
      * **(ÄÃºng) - CÃ¢u 2:** MÃ´ hÃ¬nh báº¯t chÃ­nh xÃ¡c tá»« khÃ³a `"sunny"`, `"rainy"`, `"tomorrow"` Ä‘á»ƒ dá»± Ä‘oÃ¡n `weather_query`. Táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh DL khÃ¡c Ä‘á»u sai hoÃ n toÃ n.

4.  **CÃ¢u 3 (CÃ¢u "khÃ³" nháº¥t: "...but not through paris"):**

      * ÄÃ¢y lÃ  cÃ¢u mÃ  **táº¥t cáº£ cÃ¡c mÃ´ hÃ¬nh Ä‘á»u dá»± Ä‘oÃ¡n sai**, nhÆ°ng sai theo nhá»¯ng cÃ¡ch khÃ¡c nhau.
      * **TF-IDF + LR (Sai):** Dá»± Ä‘oÃ¡n `general_negate`. Äiá»u nÃ y cho tháº¥y Ä‘iá»ƒm yáº¿u cá»§a nÃ³: nÃ³ tháº¥y "not" vÃ  bá»‹ nháº§m láº«n, nghÄ© ráº±ng Ã½ Ä‘á»‹nh cá»§a cÃ¢u lÃ  "phá»§ Ä‘á»‹nh má»™t Ä‘iá»u gÃ¬ Ä‘Ã³" thay vÃ¬ "tÃ¬m kiáº¿m thÃ´ng tin".
      * **W2V + Dense (SaiÂ²):** Dá»± Ä‘oÃ¡n `transport_query`. ÄÃ¢y lÃ  má»™t lá»—i **sai nhÆ°ng ráº¥t sÃ¡t**. NhÃ£n tháº­t lÃ  `flight_search` (tÃ¬m chuyáº¿n bay), lÃ  má»™t intent con cá»§a `transport_query` (truy váº¥n váº­n táº£i). Giá»‘ng nhÆ° CÃ¢u 1, mÃ´ hÃ¬nh nÃ y Ä‘Ã£ báº¯t Ä‘Ãºng *chá»§ Ä‘á»* nhÆ°ng sai intent cá»¥ thá»ƒ. Báº±ng cÃ¡ch láº¥y trung bÃ¬nh, nÃ³ Ä‘Ã£ bá» qua váº¿ "but not" vÃ  chá»‰ táº­p trung vÃ o cÃ¡c tá»« khÃ³a "flight", "new york", "london".

**Káº¿t luáº­n tá»« phÃ¢n tÃ­ch Ä‘á»‹nh tÃ­nh:**
KhÃ´ng cÃ³ mÃ´ hÃ¬nh nÃ o hiá»ƒu Ä‘Æ°á»£c cÃ¡c cÃ¢u phá»©c táº¡p. CÃ¡c mÃ´ hÃ¬nh LSTM (vá»‘n Ä‘Æ°á»£c ká»³ vá»ng lÃ m tá»‘t viá»‡c nÃ y) Ä‘Ã£ tháº¥t báº¡i hoÃ n toÃ n do khÃ´ng Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘á»§ (thiáº¿u dá»¯ liá»‡u, embedding kÃ©m). MÃ´ hÃ¬nh TF-IDF, dÃ¹ "ngÃ¢y thÆ¡", láº¡i lÃ  mÃ´ hÃ¬nh duy nháº¥t dá»± Ä‘oÃ¡n Ä‘Ãºng 1/3 cÃ¢u vÃ  cÃ³ 1/3 cÃ¢u sai "cháº¥p nháº­n Ä‘Æ°á»£c" (sai nhÆ°ng gáº§n Ä‘Ãºng).

-----

### âš–ï¸ Nháº­n xÃ©t chung: Æ¯u vÃ  NhÆ°á»£c Ä‘iá»ƒm

Dá»±a trÃªn cÃ¡c káº¿t quáº£ thá»±c nghiá»‡m cá»§a tÃ´i trong file notebook nÃ y:

| PhÆ°Æ¡ng phÃ¡p | Æ¯u Ä‘iá»ƒm (Pros) | NhÆ°á»£c Ä‘iá»ƒm (Cons) |
| :--- | :--- | :--- |
| **TF-IDF + Logistic Regression** | - **Hiá»‡u quáº£ nháº¥t** (F1 \> 83%).<br>- **Cá»±c ká»³ nhanh** vÃ  Ä‘Æ¡n giáº£n Ä‘á»ƒ huáº¥n luyá»‡n.<br>- Hoáº¡t Ä‘á»™ng tá»‘t nháº¥t trÃªn cÃ¡c táº­p dá»¯ liá»‡u nhá» (nhÆ° 8954 máº«u), lÃ  baseline hoÃ n háº£o. | - **KhÃ´ng hiá»ƒu thá»© tá»± tá»«** (bá»‹ Ä‘Ã¡nh lá»«a bá»Ÿi cÃ¢u "but not" vÃ  dá»± Ä‘oÃ¡n sai `general_negate`).<br>- **KhÃ´ng hiá»ƒu ngá»¯ nghÄ©a sÃ¢u** (nháº§m láº«n giá»¯a `reminder_create` vÃ  `calendar_set`). |
| **Word2Vec (Avg) + Dense** | - Báº¯t Ä‘áº§u náº¯m báº¯t Ä‘Æ°á»£c **ngá»¯ nghÄ©a** (semantic) cá»§a tá»«.<br>- Dá»± Ä‘oÃ¡n sai nhÆ°ng "gáº§n Ä‘Ãºng" á»Ÿ CÃ¢u 3 (báº¯t Ä‘Ãºng chá»§ Ä‘á» `transport`). | - **Máº¥t hoÃ n toÃ n thá»© tá»± tá»«** do láº¥y trung bÃ¬nh. ÄÃ¢y lÃ  má»™t bÆ°á»›c thÃ´ sÆ¡.<br>- Káº¿t quáº£ tá»•ng thá»ƒ ráº¥t tá»‡ (F1 \< 31%), lÃ m máº¥t quÃ¡ nhiá»u thÃ´ng tin. |
| **Embedding (Pre-trained) + LSTM** | - *LÃ½ thuyáº¿t:* Hiá»ƒu Ä‘Æ°á»£c thá»© tá»± tá»«. | - **Tháº¥t báº¡i (F1 \< 5%)**.<br>- **Embedding quÃ¡ tá»‡:** MÃ´ hÃ¬nh Word2Vec tá»± huáº¥n luyá»‡n trÃªn 8954 cÃ¢u lÃ  khÃ´ng Ä‘á»§ cháº¥t lÆ°á»£ng.<br>- **`trainable=False`:** "ÄÃ³ng bÄƒng" má»™t embedding tá»‡ lÃ  má»™t sai láº§m chÃ­ máº¡ng. |
| **Embedding (Scratch) + LSTM** | - *LÃ½ thuyáº¿t:* MÃ´ hÃ¬nh máº¡nh nháº¥t, cÃ³ thá»ƒ há»c embedding dÃ nh riÃªng cho tÃ¡c vá»¥. | - **Tháº¥t báº¡i hoÃ n toÃ n (F1 \~ 0%)**.<br>- **ÄÃ³i dá»¯ liá»‡u:** MÃ´ hÃ¬nh quÃ¡ phá»©c táº¡p so vá»›i 8954 máº«u, dáº«n Ä‘áº¿n "model collapse".<br>- Huáº¥n luyá»‡n cháº­m nháº¥t. |


### âš–ï¸ Káº¿t luáº­n chung:**
Sau khi cháº¡y cáº£ 4 mÃ´ hÃ¬nh, cÃ³ má»™t Ä‘iá»u trá»Ÿ nÃªn ráº¥t rÃµ rÃ ng: Deep Learning khÃ´ng pháº£i lÃ  "viÃªn Ä‘áº¡n báº¡c" cho má»i bÃ i toÃ¡n. Thá»±c táº¿ trong bÃ i lab nÃ y, vá»›i táº­p dá»¯ liá»‡u phÃ¢n loáº¡i vÄƒn báº£n tÆ°Æ¡ng Ä‘á»‘i nhá» (chá»‰ ~9000 máº«u), mÃ´ hÃ¬nh thá»‘ng kÃª cá»• Ä‘iá»ƒn TF-IDF + Logistic Regression Ä‘Ã£ mang láº¡i hiá»‡u quáº£ vÆ°á»£t trá»™i, chiáº¿n tháº¯ng má»™t cÃ¡ch Ã¡p Ä‘áº£o.

Trong khi Ä‘Ã³, cÃ¡c kiáº¿n trÃºc phá»©c táº¡p nhÆ° LSTM, dÃ¹ máº¡nh máº½ vá» lÃ½ thuyáº¿t, láº¡i hoÃ n toÃ n tháº¥t báº¡i. ChÃºng bá»‹ "Ä‘Ã³i" dá»¯ liá»‡u (data starvation) vÃ  khÃ´ng thá»ƒ há»c Ä‘Æ°á»£c cÃ¡c má»‘i liÃªn há»‡ phá»©c táº¡p, Ä‘áº·c biá»‡t lÃ  khi khÃ´ng cÃ³ sá»± há»— trá»£ cá»§a embedding cháº¥t lÆ°á»£ng cao (nhÆ° GloVe hay FastText). Äiá»u nÃ y dáº«n Ä‘áº¿n káº¿t quáº£ tá»‡ hÆ¡n Ä‘Ã¡ng ká»ƒ vÃ  lÃ  má»™t bÃ i há»c kinh Ä‘iá»ƒn vá» viá»‡c lá»±a chá»n mÃ´ hÃ¬nh phÃ¹ há»£p vá»›i quy mÃ´ dá»¯ liá»‡u

### TÃ i liá»‡u tham kháº£o : 
- Link github tháº§y PhÆ°Æ¡ng post trÃªn lá»›p 
- Gá»£i Ã½ code tá»« Grock
- TÃ i liá»‡u tá»« trang chá»§ tensorflow